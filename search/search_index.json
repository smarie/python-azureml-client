{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"azmlclient \u00b6 An unofficial generic client stack for AzureML web services, working with both python 2 and 3. New AzureMLClient base class to create high-level clients is here, check it out azmlclient helps you consume web services deployed on the AzureML platform easily. It provides you with a low-level API to call web services in request-response or batch mode. It also offers optional tools if you wish to provide high-level applicative APIs on top of these web services. As opposed to AzureML client library , this library is much simpler and is only focused on consuming web services. It is compliant with all services deployed from AzureML experiments (using the AzureML studio UI), and should also work with python and R \"dataframe\" web services (not checked though). It does not require your AzureML workspace id and API key, only the deployed services' URL and API key. You may use it for example to show to your customers how to consume your AzureML cloud services. to make simple 'edge' devices consume your AzureML cloud services (if they support python :) ). Installing \u00b6 > pip install azmlclient 1. Low level API \u00b6 This API is the python equivalent of the \"execute\" generic AzureML operation. It supports both request-response and batch mode, as well as swagger and non-swagger format. First examples \u00b6 First create variables holding the endpoint information provided by AzureML base_url = 'https://<geo>.services.azureml.net/workspaces/<wId>/services/<sId>' api_key = '<apiKey>' Then create the inputs - a dictionary containing all you inputs as pandas.DataFrame objects the parameters - a dictionary and optionally define a list of expected output names inputs = { \"trainDataset\" : training_df , \"input2\" : input2_df } params = { \"param1\" : \"val1\" , \"param2\" : \"val2\" } output_names = [ \"my_out1\" , \"my_out2\" ] Finally call in Request-Response mode: from azmlclient import execute_rr outputs = execute_rr ( api_key , base_url , inputs = inputs , params = params , output_names = output_names ) Or in Batch mode. In this case you also need to configure the Blob storage to be used: from azmlclient import execute_bes # Define the blob storage to use for storing inputs and outputs blob_account = '<account_id>' # 'myblobs' blob_apikey = '<api_key>' # 'mi3Qxcd5rwuM9r5k7h2ipXNww2T0Bw==' blob_container = '<container>' # 'rootcontainer' blob_path_prefix = '<path_prefix>' # 'folder/path' # Perform the call (polling is done by default every 5s until job end) outputs = execute_bes ( api_key , base_url , blob_account , blob_apikey , blob_container , blob_path_prefix = blob_path_prefix , inputs = inputs , params = params , output_names = output_names ) Formatting options \u00b6 execute_bes provides several options to control how dataframes are converted to json in the request payloads: swagger_format is a boolean (default False ) enabling the more verbose \"swagger\" (= json objects) format replace_NaN_with and replace_NaT_with control how NaN and NaT are converted Debug and proxies \u00b6 Users may wish to create a requests session object using the helper method provided, in order to override environment variable settings for HTTP requests. For example to use Fiddler as a proxy to debug the web service calls: from azmlclient import create_session_for_proxy session = create_session_for_proxy ( http_proxyhost = 'localhost' , http_proxyport = 8888 , use_http_for_https_proxy = True , ssl_verify = False ) Then you may use that object in the requests_session parameter of the methods: outputsRR = execute_rr ( ... , requests_session = session ) outputsB = execute_bes ( ... , requests_session = session ) Note that the session object will be passed to the underlying azure blob storage client to ensure consistency. Advanced usage \u00b6 Advanced users may with to create BatchClient or RequestResponseClient classes to better control what's happening. from azmlclient import RequestResponseClient # 0- Create the client rr_client = RequestResponseClient ( requests_session = requests_session ) # 1- Create the query body request_body = rr_client . create_request_body ( inputs , params ) # 2- Execute the query and receive the response body response_body = rr_client . execute_rr ( base_url , api_key , request_body ) # 3- parse the response body into a dictionary of dataframes result_dfs = rr_client . read_response_json_body ( response_body , output_names ) 2. Providing high-level APIs \u00b6 Even though the above API is enough to consume your AzureML web services, it is still very low-level: the services are not mapped to python methods with friendly names their inputs, outputs and parameters have to be created by hand from python structures changing the call mode between request-response and batch requires you to change your code there is no easy way to switch between remote and local call, for example for hybrid implementations (computationally intensive operations in the cloud, computationally cheap operations executed locally) For all these reasons, azmlclient offers tools to help you provide higher-level APIs. Creating the main client class \u00b6 Let's imagine that we have two AzureML services deployed: one for adding dataframe columns and another for subtracting them . We wish to provide our users with a more pythonic way to call them than the low-level api that we saw previously. A nice way to do this is to create a \"client class\" , that will hide away the AzureML specific syntax. We will name our class MathsProvider , it will offer one pythonic method mapped on each AzureML service: add_columns(a_name, b_name, df) and subtract_columns(a_name, b_name, df) respectively. It is extremely easy to create such a class, by inheriting from AzureMLClient . This helper base class provide a bunch of mechanisms to automate both configuration and support for alternate call modes (local, request-response, batch) as we'll see below. For each service that we want to offer, we create a method. That method should be decorated with @azureml_service , transform the received arguments (python objects) into azureml inputs and parameters dictionaries, in the same format that presented previously in the low-level api , use the self.call_azureml(...) helper function to perform the AzureML call. Note that this helper function handles the call mode (request response or batch) for you as we'll see below. unpack the various results and create the appropriate outputs (python objects) from them. For example: from azmlclient import AzureMLClient , azureml_service class MathsProvider ( AzureMLClient ): \"\"\" A client for the `add_columns` and `subtract_columns` AzureML web services \"\"\" @azureml_service def add_columns ( self , a_name , b_name , df ): \"\"\" Offers a pythonic API around the `add_columns` azureML service :param a_name: name of the first column to add (a string) :param b_name: name of the second column to add (a string) :param df: the input dataframe, that should at least contain the 2 columns selected :return: \"\"\" # (1) create the web service inputs and parameters from provided data. ws_inputs = { 'input' : df } ws_params = { 'a_name' : a_name , 'b_name' : b_name } # (2) call the azureml web service result_dfs = self . call_azureml ( self . add_columns , ws_inputs = ws_inputs , ws_params = ws_params , ws_output_names = [ 'output' ] # optional ) # (3) unpack the results return result_dfs [ 'output' ] @azureml_service def subtract_columns ( self , a_name , b_name , df ): # (similar contents than `add_columns` here) pass Using it \u00b6 Using your new client is extremely easy: simply instantiate it with a ClientConfig configuration object describing the AzureML services endpoints and you're set: from azmlclient import ClientConfig , GlobalConfig , ServiceConfig import pandas as pd # create a configuration indicating the endpoints for each service id cfg = ClientConfig ( add_columns = ServiceConfig ( base_url = \"https://.....\" , api_key = \"....\" ), subtract_columns = ServiceConfig ( base_url = \"https://.....\" , api_key = \"....\" )) # instantiate the client client = MathsProvider ( cfg ) # use it df = pd . DataFrame ({ 'x' : [ 1 , 2 , 3 ], 'y' : [ 0 , 5 , 10 ]}) result_df = client . add_columns ( 'x' , 'y' , df ) The configuration object can alternately be loaded from a .yaml file such as this one : cfg = ClientConfig . load_yaml ( yaml_file_path ) or from a configparser -compliant .ini / .cfg file such as this one : cfg = ClientConfig . load_config ( cfg_file_path ) Note that the service names in the configuration are by default the method names in your client class. If you wish to use different names, simply provide the service name to the @azureml_service decorator, for example: @azureml_service ( 'subtract_columns' ) def minus_columns ( self , a_name , b_name , df ): ... Templating \u00b6 Finally, note that the yaml and ini/cfg configuration files can be templates, using the jinja2 syntax: (...) [add_columns] base_url = https://localhost:4443/a_plus_b api_key = {{ api_key }} (...) This way, you can for example specify api keys at configuration loading time without storing them in the configuration file. Simply provide the variables and their values as keyword arguments in any of the load_config or load_yaml function: cfg = ClientConfig . load_config ( cfg_file_path , api_key = \"abc25d4789e=o\" ) Debugging \u00b6 If you wish to debug the calls made by your client, there are two things that you can do: (recommended) use a tool to capture network traffic such as Fiddler or (more complex) Wireshark . Some tools such as Fiddler require you to change to http(s) proxy. This can be done by setting the http(s)_proxy configuration option as shown below. Note that this can also be done programatically by passing a GlobalConfig(https_proxy=...,) in the ClientConfig constructor. (client_cfg.ini) [global] # (only for debug) use fiddler proxy and skip ssl verification # http_proxy = ... https_proxy = http://localhost:8888 ssl_verify = false (client_cfg.yaml) global: # (only for debug) use fiddler proxy and skip ssl verification # http_proxy = ... https_proxy = http://localhost:8888 ssl_verify: false alternatively you can use the with client.debug_requests() context manager on your client. This will print the http requests contents on stdout: with client . debug_requests (): result_df = client . add_columns ( 'x' , 'y' , df ) Alternate call modes: local, batch.. \u00b6 In the example above, client.add_columns calls the web service in request-response mode. This call mode can be changed temporarily thanks to the context managers provided: # change to BATCH mode with client . batch_calls ( polling_period_seconds = 20 ): result_df = client . add_columns ( 'x' , 'y' , df ) # change to RR mode (useless since that's already the default) with client . rr_calls (): result_df = client . add_columns ( 'x' , 'y' , df ) # change to LOCAL mode with client . local_calls (): result_df = client . add_columns ( 'x' , 'y' , df ) For the local calls by default it does not work and yields: NotImplementedError : Local execution is not available for this client . Please override ` __init_local_impl__ ` or set a non - none ` self . _local_impl ` if you wish local calls to be made available But if you override the __init_local_impl__ method and return an object on which the methods are available, it works: class MathsProviderLocal ( object ): \"\"\" A local implementation of the same services \"\"\" def add_columns ( self , a_name , b_name , df ): return pd . DataFrame ({ 'sum' : df [ a_name ] + df [ b_name ]}) def subtract_columns ( self , a_name , b_name , df ): return pd . DataFrame ({ 'diff' : df [ a_name ] - df [ b_name ]}) class MathsProvider ( AzureMLClient ): def __init_local_impl__ ( self ): \"\"\" Use our local implementation in 'local' call mode\"\"\" return MathsProviderLocal () @azureml_service def add_columns ( self , a_name , b_name , df ): ... @azureml_service def subtract_columns ( self , a_name , b_name , df ): ... we can test it : >>> with client . local_calls (): >>> result_df = client . add_columns ( 'x' , 'y' , df ) >>> print ( result_df ) sum 0 1 1 7 2 13 Note that the default call mode can also be changed permanentlyby specifying another mode in the AzureMLClient constructor arguments, or by changing the client._current_call_mode attribute. 3. Payload conversion goodies \u00b6 You can use the static methods available on the classes to convert data between json and python easily. From json to python \u00b6 You can convert the body from the HTTP web service calls into python objects using RequestResponseClient static methods: for RR requests using RequestResponseClient.decode_request_json_body(body) for RR responses using RequestResponseClient.read_response_json_body(body) For example for requests: from azmlclient import RequestResponseClient # -- read from file # with open('./request_payload.json') as f: # request_payload = f.read() # -- read from variable request_payload = \"\"\" { \"GlobalParameters\": {\"p1\": \"p1_val\", \"p2\": \"p2_val\"}, \"Inputs\": { \"trainDataset\": { \"ColumnNames\": [\"a\", \"b\"], \"Values\": [[0, 0], [1, 1], [2, 999]]} } } \"\"\" # parse the payload from a web service request to create the python equivalents dfs , params = RequestResponseClient . decode_request_json_body ( request_payload ) # display results: for input_name , df in dfs . items (): print ( \"Input %r :\" % input_name ) print ( df . head ()) print ( \"\"\" Parameters: { %s } \"\"\" % \" \\n \" . join ( \" %r : %r \" % ( k , v ) for k , v in params . items ())) yields: Input 'trainDataset' : a b 0 0 0 1 1 1 2 2 999 Parameters: { 'p1' : 'p1_val' 'p2' : 'p2_val' } From python to json \u00b6 You can create json requests and even fake responses from a RequestResponseClient instance: the json request body using rr_client.create_request_body(dfs, params) the json response body using rr_client.create_response_body(dfs) For example for the request: import pandas as pd from azmlclient import RequestResponseClient # some dataframe train_df = pd . DataFrame ( data = { 'a' : [ 0 , 1 , 2 ], 'b' : [ 1 , 2 , 3 ]}) # give it a name dfs = { 'trainDataset' : train_df } # parameters params = { 'foo' : 1 , 'bar' : 2 } # convert to json payload and print json_payload = RequestResponseClient () . create_request_body ( dfs , params ) print ( json_payload ) yields: { \"Inputs\" : { \"trainDataset\" : { \"ColumnNames\" : [ \"a\" , \"b\" ] , \"Values\" : [[ 0 , 1 ] , [ 1 , 2 ] , [ 2 , 3 ]]}} , \"GlobalParameters\" : { \"bar\" : 2 , \"foo\" : 1 }} Main features \u00b6 Creates the Web Services requests from dataframe inputs and dataframe/dictionary parameters, and maps the responses to dataframes too Maps the errors to more friendly python exceptions Supports both Request/Response and Batch mode In Batch mode, performs all the Blob storage and retrieval for you. Properly handles file encoding in both modes ( utf-8 is used by default as the pivot encoding) Supports global requests.Session configuration to configure the HTTP clients behaviour (including the underlying blob storage client). Provides tools to create higher-level clients supporting both remote and local call modes. See Also \u00b6 The official AzureML client library Others \u00b6 Do you like this library ? You might also like my other python libraries Want to contribute ? \u00b6 Details on the github page: https://github.com/smarie/python-azureml-client","title":"Home"},{"location":"#azmlclient","text":"An unofficial generic client stack for AzureML web services, working with both python 2 and 3. New AzureMLClient base class to create high-level clients is here, check it out azmlclient helps you consume web services deployed on the AzureML platform easily. It provides you with a low-level API to call web services in request-response or batch mode. It also offers optional tools if you wish to provide high-level applicative APIs on top of these web services. As opposed to AzureML client library , this library is much simpler and is only focused on consuming web services. It is compliant with all services deployed from AzureML experiments (using the AzureML studio UI), and should also work with python and R \"dataframe\" web services (not checked though). It does not require your AzureML workspace id and API key, only the deployed services' URL and API key. You may use it for example to show to your customers how to consume your AzureML cloud services. to make simple 'edge' devices consume your AzureML cloud services (if they support python :) ).","title":"azmlclient"},{"location":"#installing","text":"> pip install azmlclient","title":"Installing"},{"location":"#1-low-level-api","text":"This API is the python equivalent of the \"execute\" generic AzureML operation. It supports both request-response and batch mode, as well as swagger and non-swagger format.","title":"1. Low level API"},{"location":"#first-examples","text":"First create variables holding the endpoint information provided by AzureML base_url = 'https://<geo>.services.azureml.net/workspaces/<wId>/services/<sId>' api_key = '<apiKey>' Then create the inputs - a dictionary containing all you inputs as pandas.DataFrame objects the parameters - a dictionary and optionally define a list of expected output names inputs = { \"trainDataset\" : training_df , \"input2\" : input2_df } params = { \"param1\" : \"val1\" , \"param2\" : \"val2\" } output_names = [ \"my_out1\" , \"my_out2\" ] Finally call in Request-Response mode: from azmlclient import execute_rr outputs = execute_rr ( api_key , base_url , inputs = inputs , params = params , output_names = output_names ) Or in Batch mode. In this case you also need to configure the Blob storage to be used: from azmlclient import execute_bes # Define the blob storage to use for storing inputs and outputs blob_account = '<account_id>' # 'myblobs' blob_apikey = '<api_key>' # 'mi3Qxcd5rwuM9r5k7h2ipXNww2T0Bw==' blob_container = '<container>' # 'rootcontainer' blob_path_prefix = '<path_prefix>' # 'folder/path' # Perform the call (polling is done by default every 5s until job end) outputs = execute_bes ( api_key , base_url , blob_account , blob_apikey , blob_container , blob_path_prefix = blob_path_prefix , inputs = inputs , params = params , output_names = output_names )","title":"First examples"},{"location":"#formatting-options","text":"execute_bes provides several options to control how dataframes are converted to json in the request payloads: swagger_format is a boolean (default False ) enabling the more verbose \"swagger\" (= json objects) format replace_NaN_with and replace_NaT_with control how NaN and NaT are converted","title":"Formatting options"},{"location":"#debug-and-proxies","text":"Users may wish to create a requests session object using the helper method provided, in order to override environment variable settings for HTTP requests. For example to use Fiddler as a proxy to debug the web service calls: from azmlclient import create_session_for_proxy session = create_session_for_proxy ( http_proxyhost = 'localhost' , http_proxyport = 8888 , use_http_for_https_proxy = True , ssl_verify = False ) Then you may use that object in the requests_session parameter of the methods: outputsRR = execute_rr ( ... , requests_session = session ) outputsB = execute_bes ( ... , requests_session = session ) Note that the session object will be passed to the underlying azure blob storage client to ensure consistency.","title":"Debug and proxies"},{"location":"#advanced-usage","text":"Advanced users may with to create BatchClient or RequestResponseClient classes to better control what's happening. from azmlclient import RequestResponseClient # 0- Create the client rr_client = RequestResponseClient ( requests_session = requests_session ) # 1- Create the query body request_body = rr_client . create_request_body ( inputs , params ) # 2- Execute the query and receive the response body response_body = rr_client . execute_rr ( base_url , api_key , request_body ) # 3- parse the response body into a dictionary of dataframes result_dfs = rr_client . read_response_json_body ( response_body , output_names )","title":"Advanced usage"},{"location":"#2-providing-high-level-apis","text":"Even though the above API is enough to consume your AzureML web services, it is still very low-level: the services are not mapped to python methods with friendly names their inputs, outputs and parameters have to be created by hand from python structures changing the call mode between request-response and batch requires you to change your code there is no easy way to switch between remote and local call, for example for hybrid implementations (computationally intensive operations in the cloud, computationally cheap operations executed locally) For all these reasons, azmlclient offers tools to help you provide higher-level APIs.","title":"2. Providing high-level APIs"},{"location":"#creating-the-main-client-class","text":"Let's imagine that we have two AzureML services deployed: one for adding dataframe columns and another for subtracting them . We wish to provide our users with a more pythonic way to call them than the low-level api that we saw previously. A nice way to do this is to create a \"client class\" , that will hide away the AzureML specific syntax. We will name our class MathsProvider , it will offer one pythonic method mapped on each AzureML service: add_columns(a_name, b_name, df) and subtract_columns(a_name, b_name, df) respectively. It is extremely easy to create such a class, by inheriting from AzureMLClient . This helper base class provide a bunch of mechanisms to automate both configuration and support for alternate call modes (local, request-response, batch) as we'll see below. For each service that we want to offer, we create a method. That method should be decorated with @azureml_service , transform the received arguments (python objects) into azureml inputs and parameters dictionaries, in the same format that presented previously in the low-level api , use the self.call_azureml(...) helper function to perform the AzureML call. Note that this helper function handles the call mode (request response or batch) for you as we'll see below. unpack the various results and create the appropriate outputs (python objects) from them. For example: from azmlclient import AzureMLClient , azureml_service class MathsProvider ( AzureMLClient ): \"\"\" A client for the `add_columns` and `subtract_columns` AzureML web services \"\"\" @azureml_service def add_columns ( self , a_name , b_name , df ): \"\"\" Offers a pythonic API around the `add_columns` azureML service :param a_name: name of the first column to add (a string) :param b_name: name of the second column to add (a string) :param df: the input dataframe, that should at least contain the 2 columns selected :return: \"\"\" # (1) create the web service inputs and parameters from provided data. ws_inputs = { 'input' : df } ws_params = { 'a_name' : a_name , 'b_name' : b_name } # (2) call the azureml web service result_dfs = self . call_azureml ( self . add_columns , ws_inputs = ws_inputs , ws_params = ws_params , ws_output_names = [ 'output' ] # optional ) # (3) unpack the results return result_dfs [ 'output' ] @azureml_service def subtract_columns ( self , a_name , b_name , df ): # (similar contents than `add_columns` here) pass","title":"Creating the main client class"},{"location":"#using-it","text":"Using your new client is extremely easy: simply instantiate it with a ClientConfig configuration object describing the AzureML services endpoints and you're set: from azmlclient import ClientConfig , GlobalConfig , ServiceConfig import pandas as pd # create a configuration indicating the endpoints for each service id cfg = ClientConfig ( add_columns = ServiceConfig ( base_url = \"https://.....\" , api_key = \"....\" ), subtract_columns = ServiceConfig ( base_url = \"https://.....\" , api_key = \"....\" )) # instantiate the client client = MathsProvider ( cfg ) # use it df = pd . DataFrame ({ 'x' : [ 1 , 2 , 3 ], 'y' : [ 0 , 5 , 10 ]}) result_df = client . add_columns ( 'x' , 'y' , df ) The configuration object can alternately be loaded from a .yaml file such as this one : cfg = ClientConfig . load_yaml ( yaml_file_path ) or from a configparser -compliant .ini / .cfg file such as this one : cfg = ClientConfig . load_config ( cfg_file_path ) Note that the service names in the configuration are by default the method names in your client class. If you wish to use different names, simply provide the service name to the @azureml_service decorator, for example: @azureml_service ( 'subtract_columns' ) def minus_columns ( self , a_name , b_name , df ): ...","title":"Using it"},{"location":"#templating","text":"Finally, note that the yaml and ini/cfg configuration files can be templates, using the jinja2 syntax: (...) [add_columns] base_url = https://localhost:4443/a_plus_b api_key = {{ api_key }} (...) This way, you can for example specify api keys at configuration loading time without storing them in the configuration file. Simply provide the variables and their values as keyword arguments in any of the load_config or load_yaml function: cfg = ClientConfig . load_config ( cfg_file_path , api_key = \"abc25d4789e=o\" )","title":"Templating"},{"location":"#debugging","text":"If you wish to debug the calls made by your client, there are two things that you can do: (recommended) use a tool to capture network traffic such as Fiddler or (more complex) Wireshark . Some tools such as Fiddler require you to change to http(s) proxy. This can be done by setting the http(s)_proxy configuration option as shown below. Note that this can also be done programatically by passing a GlobalConfig(https_proxy=...,) in the ClientConfig constructor. (client_cfg.ini) [global] # (only for debug) use fiddler proxy and skip ssl verification # http_proxy = ... https_proxy = http://localhost:8888 ssl_verify = false (client_cfg.yaml) global: # (only for debug) use fiddler proxy and skip ssl verification # http_proxy = ... https_proxy = http://localhost:8888 ssl_verify: false alternatively you can use the with client.debug_requests() context manager on your client. This will print the http requests contents on stdout: with client . debug_requests (): result_df = client . add_columns ( 'x' , 'y' , df )","title":"Debugging"},{"location":"#alternate-call-modes-local-batch","text":"In the example above, client.add_columns calls the web service in request-response mode. This call mode can be changed temporarily thanks to the context managers provided: # change to BATCH mode with client . batch_calls ( polling_period_seconds = 20 ): result_df = client . add_columns ( 'x' , 'y' , df ) # change to RR mode (useless since that's already the default) with client . rr_calls (): result_df = client . add_columns ( 'x' , 'y' , df ) # change to LOCAL mode with client . local_calls (): result_df = client . add_columns ( 'x' , 'y' , df ) For the local calls by default it does not work and yields: NotImplementedError : Local execution is not available for this client . Please override ` __init_local_impl__ ` or set a non - none ` self . _local_impl ` if you wish local calls to be made available But if you override the __init_local_impl__ method and return an object on which the methods are available, it works: class MathsProviderLocal ( object ): \"\"\" A local implementation of the same services \"\"\" def add_columns ( self , a_name , b_name , df ): return pd . DataFrame ({ 'sum' : df [ a_name ] + df [ b_name ]}) def subtract_columns ( self , a_name , b_name , df ): return pd . DataFrame ({ 'diff' : df [ a_name ] - df [ b_name ]}) class MathsProvider ( AzureMLClient ): def __init_local_impl__ ( self ): \"\"\" Use our local implementation in 'local' call mode\"\"\" return MathsProviderLocal () @azureml_service def add_columns ( self , a_name , b_name , df ): ... @azureml_service def subtract_columns ( self , a_name , b_name , df ): ... we can test it : >>> with client . local_calls (): >>> result_df = client . add_columns ( 'x' , 'y' , df ) >>> print ( result_df ) sum 0 1 1 7 2 13 Note that the default call mode can also be changed permanentlyby specifying another mode in the AzureMLClient constructor arguments, or by changing the client._current_call_mode attribute.","title":"Alternate call modes: local, batch.."},{"location":"#3-payload-conversion-goodies","text":"You can use the static methods available on the classes to convert data between json and python easily.","title":"3. Payload conversion goodies"},{"location":"#from-json-to-python","text":"You can convert the body from the HTTP web service calls into python objects using RequestResponseClient static methods: for RR requests using RequestResponseClient.decode_request_json_body(body) for RR responses using RequestResponseClient.read_response_json_body(body) For example for requests: from azmlclient import RequestResponseClient # -- read from file # with open('./request_payload.json') as f: # request_payload = f.read() # -- read from variable request_payload = \"\"\" { \"GlobalParameters\": {\"p1\": \"p1_val\", \"p2\": \"p2_val\"}, \"Inputs\": { \"trainDataset\": { \"ColumnNames\": [\"a\", \"b\"], \"Values\": [[0, 0], [1, 1], [2, 999]]} } } \"\"\" # parse the payload from a web service request to create the python equivalents dfs , params = RequestResponseClient . decode_request_json_body ( request_payload ) # display results: for input_name , df in dfs . items (): print ( \"Input %r :\" % input_name ) print ( df . head ()) print ( \"\"\" Parameters: { %s } \"\"\" % \" \\n \" . join ( \" %r : %r \" % ( k , v ) for k , v in params . items ())) yields: Input 'trainDataset' : a b 0 0 0 1 1 1 2 2 999 Parameters: { 'p1' : 'p1_val' 'p2' : 'p2_val' }","title":"From json to python"},{"location":"#from-python-to-json","text":"You can create json requests and even fake responses from a RequestResponseClient instance: the json request body using rr_client.create_request_body(dfs, params) the json response body using rr_client.create_response_body(dfs) For example for the request: import pandas as pd from azmlclient import RequestResponseClient # some dataframe train_df = pd . DataFrame ( data = { 'a' : [ 0 , 1 , 2 ], 'b' : [ 1 , 2 , 3 ]}) # give it a name dfs = { 'trainDataset' : train_df } # parameters params = { 'foo' : 1 , 'bar' : 2 } # convert to json payload and print json_payload = RequestResponseClient () . create_request_body ( dfs , params ) print ( json_payload ) yields: { \"Inputs\" : { \"trainDataset\" : { \"ColumnNames\" : [ \"a\" , \"b\" ] , \"Values\" : [[ 0 , 1 ] , [ 1 , 2 ] , [ 2 , 3 ]]}} , \"GlobalParameters\" : { \"bar\" : 2 , \"foo\" : 1 }}","title":"From python to json"},{"location":"#main-features","text":"Creates the Web Services requests from dataframe inputs and dataframe/dictionary parameters, and maps the responses to dataframes too Maps the errors to more friendly python exceptions Supports both Request/Response and Batch mode In Batch mode, performs all the Blob storage and retrieval for you. Properly handles file encoding in both modes ( utf-8 is used by default as the pivot encoding) Supports global requests.Session configuration to configure the HTTP clients behaviour (including the underlying blob storage client). Provides tools to create higher-level clients supporting both remote and local call modes.","title":"Main features"},{"location":"#see-also","text":"The official AzureML client library","title":"See Also"},{"location":"#others","text":"Do you like this library ? You might also like my other python libraries","title":"Others"},{"location":"#want-to-contribute","text":"Details on the github page: https://github.com/smarie/python-azureml-client","title":"Want to contribute ?"},{"location":"changelog/","text":"Changelog \u00b6 2.5.0 - New replace_NaN_with and replace_NaT_with options \u00b6 New replace_NaN_with and replace_NaT_with options to control how NaN and NaT get converted. Fixes #11 packaging improvements: set the \"universal wheel\" flag to 1, and cleaned up the setup.py . In particular removed dependency to six for setup and added py.typed file. Added pyproject.toml too. Fixes #13 2.4.0 - new helper method + doc \u00b6 New method create_response_body in RequestResponseClient . Updated doc to show how these goodies can be used. 2.3.2 - added __version__ attribute \u00b6 Added __version__ at package level. 2.3.1 - Config files can now be templates \u00b6 ClientConfig.load_config() now accepts keyword arguments that will be used as replacements for variables in the config files. Fixes #10 . New dependency: jinja2 2.2.0 - Request-Response: new default behaviour concerning outputs, and new parameter. \u00b6 Low-level API: RequestResponseClient.read_response_json_body now does not filter outputs anymore even if a non-None output_names is provided. New parameter to execute_rr : only_keep_selected_output_names . If this is True the legacy behaviour of filtering outputs by names is preserved. Otherwise all outputs are preserved. Fixes #9 High-level API: AzureMLClient.call_azureml : ws_output_names now appears as optional in the type hints. Improved docstring comments slightly. 2.1.0 - High-level clients: swagger, remote-only services + Bugfix \u00b6 New: Swagger format is now supported in both high-level (call modes) and low-level (RR and Batch clients) API. Fixes #5 . New argument remote_only to disable local usage of a service. Fixes #8 . Misc: Fixed bug with decoding AzureML errors. Fixes #7 . call_local_service : renamed argument service_name to function_name to distinguish better between the service (azureml) and the function (local implementation's method). 2.0.0 - New tools for high level api creation \u00b6 New features: AzureMLClient helper class to create pythonic high-level APIs, supporting both local and remote call modes, and configurable from yaml and ini/cfg files. Refactoring: azure-storage dependency is now optional (only for batch mode) improved documentation and type hints, and changed some method names and contents to be more pythonic. This was indeed a quite old project :). removed use_new_ws from all methods - this concept is not meaningful anymore for AzureML usage. renamed RR_Client into RequestResponseClient and Batch_Client into BatchClient . Old names will stay around for a version or two for compatibility reasons. got rid of the useless Converters container classes for data binding. 1.2.0 - Support for \"swagger\" mode \u00b6 Added swagger=True mode support for azureML calls 1.1.0 - Python 2 support, and a few bugfixes \u00b6 Updated this old project (my first public python package :) ) to more recent continuous integration and tests standards. Support for python 2 A few bugfixes Added all correct dependencies in setup.py 1.0.1 - First version \u00b6 Request-response and Batch modes support, python 3 only.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#250-new-replace_nan_with-and-replace_nat_with-options","text":"New replace_NaN_with and replace_NaT_with options to control how NaN and NaT get converted. Fixes #11 packaging improvements: set the \"universal wheel\" flag to 1, and cleaned up the setup.py . In particular removed dependency to six for setup and added py.typed file. Added pyproject.toml too. Fixes #13","title":"2.5.0 - New replace_NaN_with and replace_NaT_with options"},{"location":"changelog/#240-new-helper-method-doc","text":"New method create_response_body in RequestResponseClient . Updated doc to show how these goodies can be used.","title":"2.4.0 - new helper method + doc"},{"location":"changelog/#232-added-__version__-attribute","text":"Added __version__ at package level.","title":"2.3.2 - added __version__ attribute"},{"location":"changelog/#231-config-files-can-now-be-templates","text":"ClientConfig.load_config() now accepts keyword arguments that will be used as replacements for variables in the config files. Fixes #10 . New dependency: jinja2","title":"2.3.1 - Config files can now be templates"},{"location":"changelog/#220-request-response-new-default-behaviour-concerning-outputs-and-new-parameter","text":"Low-level API: RequestResponseClient.read_response_json_body now does not filter outputs anymore even if a non-None output_names is provided. New parameter to execute_rr : only_keep_selected_output_names . If this is True the legacy behaviour of filtering outputs by names is preserved. Otherwise all outputs are preserved. Fixes #9 High-level API: AzureMLClient.call_azureml : ws_output_names now appears as optional in the type hints. Improved docstring comments slightly.","title":"2.2.0 - Request-Response: new default behaviour concerning outputs, and new parameter."},{"location":"changelog/#210-high-level-clients-swagger-remote-only-services-bugfix","text":"New: Swagger format is now supported in both high-level (call modes) and low-level (RR and Batch clients) API. Fixes #5 . New argument remote_only to disable local usage of a service. Fixes #8 . Misc: Fixed bug with decoding AzureML errors. Fixes #7 . call_local_service : renamed argument service_name to function_name to distinguish better between the service (azureml) and the function (local implementation's method).","title":"2.1.0 - High-level clients: swagger, remote-only services + Bugfix"},{"location":"changelog/#200-new-tools-for-high-level-api-creation","text":"New features: AzureMLClient helper class to create pythonic high-level APIs, supporting both local and remote call modes, and configurable from yaml and ini/cfg files. Refactoring: azure-storage dependency is now optional (only for batch mode) improved documentation and type hints, and changed some method names and contents to be more pythonic. This was indeed a quite old project :). removed use_new_ws from all methods - this concept is not meaningful anymore for AzureML usage. renamed RR_Client into RequestResponseClient and Batch_Client into BatchClient . Old names will stay around for a version or two for compatibility reasons. got rid of the useless Converters container classes for data binding.","title":"2.0.0 - New tools for high level api creation"},{"location":"changelog/#120-support-for-swagger-mode","text":"Added swagger=True mode support for azureML calls","title":"1.2.0 - Support for \"swagger\" mode"},{"location":"changelog/#110-python-2-support-and-a-few-bugfixes","text":"Updated this old project (my first public python package :) ) to more recent continuous integration and tests standards. Support for python 2 A few bugfixes Added all correct dependencies in setup.py","title":"1.1.0 - Python 2 support, and a few bugfixes"},{"location":"changelog/#101-first-version","text":"Request-response and Batch modes support, python 3 only.","title":"1.0.1 - First version"},{"location":"long_description/","text":"azmlclient \u00b6 An unofficial generic client stack for azureML web services, working with both python 2 and 3. The documentation for users is available here: https://smarie.github.io/python-azureml-client/ A readme for developers is available here: https://github.com/smarie/python-azureml-client","title":"azmlclient"},{"location":"long_description/#azmlclient","text":"An unofficial generic client stack for azureML web services, working with both python 2 and 3. The documentation for users is available here: https://smarie.github.io/python-azureml-client/ A readme for developers is available here: https://github.com/smarie/python-azureml-client","title":"azmlclient"}]}